---
phase: 09-bank-vault-architecture
plan: 06
type: execute
wave: 2
depends_on: ["09-04", "09-05"]
files_modified:
  - supabase/migrations/20260131000008_migration_function.sql
  - supabase/functions/migrate-recordings/index.ts
autonomous: true

must_haves:
  truths:
    - "Migration function converts fathom_calls to recordings + vault_entries"
    - "Migration is idempotent (re-running doesn't create duplicates)"
    - "All existing user calls end up in their personal vault"
  artifacts:
    - path: "supabase/migrations/20260131000008_migration_function.sql"
      provides: "migrate_fathom_call_to_recording() function"
      contains: "CREATE OR REPLACE FUNCTION migrate_fathom_call_to_recording"
    - path: "supabase/functions/migrate-recordings/index.ts"
      provides: "Background migration Edge Function"
      contains: "migrate-recordings"
  key_links:
    - from: "migrate_fathom_call_to_recording()"
      to: "recordings"
      via: "INSERT"
      pattern: "INSERT INTO recordings"
    - from: "migrate_fathom_call_to_recording()"
      to: "vault_entries"
      via: "INSERT"
      pattern: "INSERT INTO vault_entries"
---

<objective>
Create the migration function and background migration Edge Function to convert existing fathom_calls to the new recordings + vault_entries structure. Each user's existing calls become VaultEntries in their personal vault.

Purpose: Migrate existing data to the new Bank/Vault model without data loss. The migration is idempotent to allow safe re-runs.
Output: SQL migration function + Edge Function for batch processing, all existing calls migrated to personal vaults.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-bank-vault-architecture/09-CONTEXT.md
@.planning/phases/09-bank-vault-architecture/09-RESEARCH.md
@docs/planning/CallVault-Final-Spaces.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create migration SQL function</name>
  <files>supabase/migrations/20260131000008_migration_function.sql</files>
  <action>
Create the migration function per RESEARCH.md pattern:

```sql
-- Function to migrate a single fathom_call to recording + vault_entry
-- Per CONTEXT.md: Each user's existing calls become VaultEntries in their Personal Vault
CREATE OR REPLACE FUNCTION migrate_fathom_call_to_recording(
  p_recording_id BIGINT,
  p_user_id UUID
)
RETURNS UUID -- Returns new recording UUID
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  v_bank_id UUID;
  v_vault_id UUID;
  v_new_recording_id UUID;
  v_call RECORD;
BEGIN
  -- Get user's personal bank
  SELECT b.id INTO v_bank_id
  FROM banks b
  JOIN bank_memberships bm ON bm.bank_id = b.id
  WHERE bm.user_id = p_user_id
    AND b.type = 'personal'
  LIMIT 1;
  
  IF v_bank_id IS NULL THEN
    -- User doesn't have a personal bank yet - create one
    INSERT INTO banks (name, type)
    VALUES ('Personal', 'personal')
    RETURNING id INTO v_bank_id;
    
    INSERT INTO bank_memberships (bank_id, user_id, role)
    VALUES (v_bank_id, p_user_id, 'bank_owner');
  END IF;
  
  -- Get user's personal vault
  SELECT v.id INTO v_vault_id
  FROM vaults v
  JOIN vault_memberships vm ON vm.vault_id = v.id
  WHERE vm.user_id = p_user_id
    AND v.bank_id = v_bank_id
    AND v.vault_type = 'personal'
  LIMIT 1;
  
  IF v_vault_id IS NULL THEN
    -- User doesn't have a personal vault yet - create one
    INSERT INTO vaults (bank_id, name, vault_type)
    VALUES (v_bank_id, 'My Calls', 'personal')
    RETURNING id INTO v_vault_id;
    
    INSERT INTO vault_memberships (vault_id, user_id, role)
    VALUES (v_vault_id, p_user_id, 'vault_owner');
  END IF;
  
  -- Check if already migrated (idempotency)
  SELECT id INTO v_new_recording_id
  FROM recordings
  WHERE legacy_recording_id = p_recording_id AND bank_id = v_bank_id;
  
  IF v_new_recording_id IS NOT NULL THEN
    -- Already migrated, return existing
    RETURN v_new_recording_id;
  END IF;
  
  -- Get the fathom_call data
  SELECT * INTO v_call
  FROM fathom_calls
  WHERE recording_id = p_recording_id AND user_id = p_user_id;
  
  IF v_call IS NULL THEN
    RAISE EXCEPTION 'Call not found: % / %', p_recording_id, p_user_id;
  END IF;
  
  -- Create recording
  INSERT INTO recordings (
    legacy_recording_id,
    bank_id,
    owner_user_id,
    title,
    audio_url,
    video_url,
    full_transcript,
    summary,
    global_tags,
    source_app,
    source_metadata,
    duration,
    recording_start_time,
    recording_end_time,
    created_at,
    synced_at
  ) VALUES (
    v_call.recording_id,
    v_bank_id,
    p_user_id,
    v_call.title,
    v_call.audio_url,
    v_call.video_url,
    v_call.full_transcript,
    v_call.summary,
    COALESCE(v_call.auto_tags, '{}'),
    COALESCE(v_call.source_platform, 'fathom'),
    COALESCE(v_call.metadata, '{}')::JSONB,
    v_call.duration,
    v_call.recording_start_time,
    v_call.recording_end_time,
    v_call.created_at,
    v_call.synced_at
  )
  RETURNING id INTO v_new_recording_id;
  
  -- Create vault entry in personal vault
  INSERT INTO vault_entries (
    vault_id,
    recording_id,
    local_tags,
    created_at
  ) VALUES (
    v_vault_id,
    v_new_recording_id,
    '{}', -- Start with empty local tags
    v_call.created_at
  );
  
  RETURN v_new_recording_id;
END;
$$;

-- Batch migration function for background processing
CREATE OR REPLACE FUNCTION migrate_batch_fathom_calls(
  p_batch_size INTEGER DEFAULT 100
)
RETURNS TABLE(migrated_count INTEGER, error_count INTEGER)
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  v_migrated INTEGER := 0;
  v_errors INTEGER := 0;
  v_call RECORD;
BEGIN
  -- Get batch of calls not yet migrated
  FOR v_call IN
    SELECT fc.recording_id, fc.user_id
    FROM fathom_calls fc
    WHERE NOT EXISTS (
      SELECT 1 FROM recordings r
      WHERE r.legacy_recording_id = fc.recording_id
    )
    LIMIT p_batch_size
  LOOP
    BEGIN
      PERFORM migrate_fathom_call_to_recording(v_call.recording_id, v_call.user_id);
      v_migrated := v_migrated + 1;
    EXCEPTION WHEN OTHERS THEN
      v_errors := v_errors + 1;
      -- Log error but continue
      RAISE WARNING 'Migration failed for recording % user %: %', v_call.recording_id, v_call.user_id, SQLERRM;
    END;
  END LOOP;
  
  RETURN QUERY SELECT v_migrated, v_errors;
END;
$$;
```

Key behaviors:
- Creates bank/vault if user doesn't have one (handles legacy users)
- Idempotent: returns existing ID if already migrated
- Maps fathom_calls columns to recordings columns
- Creates vault_entry in personal vault
- Batch function for background processing
  </action>
  <verify>
- Migration applies without errors
- Test: `SELECT migrate_fathom_call_to_recording(123, 'user-uuid')` works
- Test: Running twice returns same ID (idempotent)
  </verify>
  <done>
- migrate_fathom_call_to_recording() function created
- migrate_batch_fathom_calls() for batch processing
- Handles missing bank/vault creation
- Idempotent (safe to re-run)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create background migration Edge Function</name>
  <files>supabase/functions/migrate-recordings/index.ts</files>
  <action>
Create Edge Function following existing patterns in supabase/functions/:

```typescript
// supabase/functions/migrate-recordings/index.ts
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { corsHeaders, getCorsHeaders } from '../_shared/cors.ts'

const BATCH_SIZE = 100

Deno.serve(async (req) => {
  // Handle CORS
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: getCorsHeaders(req) })
  }

  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    
    // Use service role for migration (bypasses RLS)
    const supabase = createClient(supabaseUrl, serviceRoleKey)
    
    // Check if caller is admin
    const authHeader = req.headers.get('Authorization')
    if (!authHeader) {
      return new Response(
        JSON.stringify({ error: 'Authorization required' }),
        { status: 401, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
      )
    }
    
    // Verify caller has admin role
    const { data: { user }, error: authError } = await supabase.auth.getUser(
      authHeader.replace('Bearer ', '')
    )
    
    if (authError || !user) {
      return new Response(
        JSON.stringify({ error: 'Invalid token' }),
        { status: 401, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
      )
    }
    
    // Check admin role
    const { data: roleData } = await supabase
      .from('user_roles')
      .select('role')
      .eq('user_id', user.id)
      .eq('role', 'ADMIN')
      .single()
    
    if (!roleData) {
      return new Response(
        JSON.stringify({ error: 'Admin access required' }),
        { status: 403, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
      )
    }
    
    // Get migration stats before
    const { count: totalCalls } = await supabase
      .from('fathom_calls')
      .select('*', { count: 'exact', head: true })
    
    const { count: migratedCalls } = await supabase
      .from('recordings')
      .select('*', { count: 'exact', head: true })
      .not('legacy_recording_id', 'is', null)
    
    // Run batch migration
    const { data: result, error: migrationError } = await supabase
      .rpc('migrate_batch_fathom_calls', { p_batch_size: BATCH_SIZE })
    
    if (migrationError) {
      console.error('Migration error:', migrationError)
      return new Response(
        JSON.stringify({ error: migrationError.message }),
        { status: 500, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
      )
    }
    
    const migrated = result?.[0]?.migrated_count ?? 0
    const errors = result?.[0]?.error_count ?? 0
    
    // Get updated stats
    const { count: newMigratedCount } = await supabase
      .from('recordings')
      .select('*', { count: 'exact', head: true })
      .not('legacy_recording_id', 'is', null)
    
    const remaining = (totalCalls ?? 0) - (newMigratedCount ?? 0)
    
    return new Response(
      JSON.stringify({
        success: true,
        batch: {
          migrated,
          errors,
          batch_size: BATCH_SIZE
        },
        overall: {
          total_calls: totalCalls,
          migrated: newMigratedCount,
          remaining,
          complete: remaining === 0
        }
      }),
      { status: 200, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
    )
    
  } catch (err) {
    console.error('Unexpected error:', err)
    return new Response(
      JSON.stringify({ error: 'Internal server error' }),
      { status: 500, headers: { ...getCorsHeaders(req), 'Content-Type': 'application/json' } }
    )
  }
})
```

Key features:
- Admin-only access (checks user_roles)
- Uses service role to bypass RLS
- Calls migrate_batch_fathom_calls RPC
- Returns progress stats (total, migrated, remaining)
- Can be called repeatedly until complete=true
  </action>
  <verify>
- Edge Function deploys: `supabase functions deploy migrate-recordings`
- Test: Call with admin token, verify batch runs
- Test: Call repeatedly, verify progress increases
- **SQL count verification after batch:**
  - Before: `SELECT COUNT(*) FROM recordings WHERE legacy_recording_id IS NOT NULL` → note count
  - Run migration batch via Edge Function
  - After: Same query → count increased by batch_size (or remaining calls)
  - Verify: `overall.migrated` in response matches new count
  </verify>
  <done>
- Edge Function created at migrate-recordings/
- Admin-only access control
- Uses batch RPC for safe processing
- Returns progress stats for monitoring
  </done>
</task>

</tasks>

<verification>
1. Migrations apply: `supabase db push`
2. Functions exist: `SELECT proname FROM pg_proc WHERE proname LIKE 'migrate%'`
3. Edge Function deploys successfully
4. Test migration on single call works
5. Batch migration processes 100 calls at a time
</verification>

<success_criteria>
- migrate_fathom_call_to_recording() handles all column mappings
- Migration creates bank/vault if missing
- Idempotent (safe to re-run)
- Batch function processes in chunks of 100
- Edge Function is admin-only
- Progress tracking works
</success_criteria>

<output>
After completion, create `.planning/phases/09-bank-vault-architecture/09-06-SUMMARY.md`
</output>
